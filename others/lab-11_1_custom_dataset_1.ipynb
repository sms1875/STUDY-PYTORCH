{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    모두를 위한 딥러닝 시즌2 pytorch\n",
    "    *** Custom Dataset은 어떻게 쓰나요? (1)***\n",
    "    맨날 나오는 MNIST가 지겨워서 새로운 데이터셋을 만들어 봤습니다.\n",
    "    여러분이 가지고 있는 사진을 분류해보고 싶을수 있으니 아래 프로젝트를 따라가면서\n",
    "    내가 가진 사진을 어떻게 학습시키는지 익혀봅시다!\n",
    "\n",
    "    상황 설명 =>\n",
    "    저는 Naver CONNECT 재단에 있는 빨간색의자와 회색의자를 구분하고 싶었어요!\n",
    "    그런데 사진을 어떻게 가져오고 어떻게 입력해야 되는지 잘 모르겠어요!!\n",
    "\n",
    "    시작!\n",
    "\n",
    "    torchvision.datasets.ImageFolder는 내가 가지고 있는 사진을 이용하는 방법입니다.\n",
    "\n",
    "    가지고 있는 사진을 아래와 같이 구분해 두고 시작합니다.\n",
    "\n",
    "    지금 폴더에\n",
    "    origin_data라는 폴더를 만들고!(=> ./origin_data) {./ 에서 . <= 요 점이 현 위치를 의미한다는거 아시죠?}\n",
    "    origin_data폴더 안에 구분할 의자별 폴더를 만듭니다. (=>./origin_data/red & ./origin_data/\\gray)\n",
    "    이제 각 폴더에 색깔별로 넣으면 됩니다.\n",
    "\n",
    "    ./origin_data\n",
    "            |-----red\n",
    "            |-----gray\n",
    "\n",
    "\n",
    "\n",
    "    torchvision.datasets.ImageFolder는 다음과 같은 내용을 인자로 받습니다.\n",
    "\n",
    "    root                          = 내 폴더의 위치를 str 값으로 입력 받음\n",
    "    transform(optional)           = 입력받을 데이터들을 원하는 형태로 수정하는 방법입니다.\n",
    "                                    torch는 입력 값이 무조건 tensor여야 하는데 여기서 하면 되겠지요?\n",
    "                                    모르시겠다면 앞에 xx강을 참조하세요!\n",
    "    target_transform(optional)    = A function/transform that takes in the target and transforms it.\n",
    "    loader                        = A function to load an image given its path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "data=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .py file 과는 다르게 이미지를 보기 위해서는 matplotlib의 pyplot를 이용해서 이미지를 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=torchvision.datasets.ImageFolder(root='./origin_data',transform=None)\n",
    "\n",
    "for num, value in enumerate(train_data):\n",
    "    data, label = value\n",
    "                \n",
    "    #imshow(data)\n",
    "    #break\n",
    "\n",
    "    print(num, data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
